<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-08-10T15:00:27+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">James’ HomePage</title><subtitle>这是一个初学博客的博主</subtitle><author><name>true</name></author><entry><title type="html">北大退档事件</title><link href="http://localhost:4000/2019/08/10/%E5%8C%97%E5%A4%A7%E9%80%80%E6%A1%A3%E4%BA%8B%E4%BB%B6.html" rel="alternate" type="text/html" title="北大退档事件" /><published>2019-08-10T00:00:00+08:00</published><updated>2019-08-10T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/10/%E5%8C%97%E5%A4%A7%E9%80%80%E6%A1%A3%E4%BA%8B%E4%BB%B6</id><content type="html" xml:base="http://localhost:4000/2019/08/10/%E5%8C%97%E5%A4%A7%E9%80%80%E6%A1%A3%E4%BA%8B%E4%BB%B6.html">&lt;h1 id=&quot;北大退档事件&quot;&gt;北大退档事件&lt;/h1&gt;

&lt;p&gt;  知道这件事情的我是出离愤怒的，在提档操作完全合理合法的前提下以臆想多次要求退档，这种操作完全超出我的理解范围。
  我国是社会主义国家，我们最引以为傲的就是国家不遗余力的投资落后地区，教育、基础设施、工厂企业，为的就是实现共同富裕。高考按省份招生正是这一观点的延伸，确保落后地区能够有足够数量的学生在全国顶尖的高校接受教育，专项计划也一样，虽然其在实际执行中或许会存在舞弊的现象，但是于理于法这都是校方必须接受的规定。
  提档后有权退档是高校选拔学生的自主权，但绝对不是高校以主观臆断拒绝专项计划学生的挡箭牌，更不用说北大作为全国高校中的翘楚，若其他高校纷纷效仿将会给落后地区或者贫困家庭带来什么样的影响，我国我党坚持的扶贫政策就这样从人民心目中高大的北京大学这里率先垮掉。
  过去也曾想过高等教育改革，我作为一名省会城市重点高中的学生，拿着全省最优秀的资源，自然不曾想过在大山深处有多少贫困的学生挣扎着希望通过接受高等教育来改变自己的命运。成熟后的今天我知道，在中国没有彻底实现全体小康之前，像西方那样完全放开高校招生自主权的教育制度是完全不可能的，上了大学之后身边有很多同学是来自祖国各地的山村的，他们有些连电脑都不舍得买，拼拼凑凑弄出来一个廉价的台式机出来，而成绩却并不见得很差，我的一个直系学弟甚至是我们实验班的前三名。一个国家有一个国家的国情，如果都像北大这样以主观臆断拒绝已经提档的学生，那我国的贫富分化将会以坐火箭的速度向上飞去！
  希望北京大学能给公众一个合理的交代，一个诚恳的道歉，而不是站在高处拿着所谓的高校自主权作为挡箭牌欺骗广大的韭菜们！&lt;/p&gt;</content><author><name>James</name></author><category term="随笔" /><summary type="html">北大退档事件</summary></entry><entry><title type="html">ROS 内参标定</title><link href="http://localhost:4000/2019/08/09/ROS-%E5%86%85%E5%8F%82%E6%A0%87%E5%AE%9A.html" rel="alternate" type="text/html" title="ROS 内参标定" /><published>2019-08-09T00:00:00+08:00</published><updated>2019-08-09T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/09/ROS%20%E5%86%85%E5%8F%82%E6%A0%87%E5%AE%9A</id><content type="html" xml:base="http://localhost:4000/2019/08/09/ROS-%E5%86%85%E5%8F%82%E6%A0%87%E5%AE%9A.html">&lt;h1 id=&quot;ros-内参标定&quot;&gt;ROS 内参标定&lt;/h1&gt;

&lt;p&gt;​		  在这一小节中我们将会介绍如何使用Intel的Realsense D415相机的RGB部分进行内参的标定，除此之外也会使用笔记本电脑自带的摄像头进行标定以让每一位同学都能有机会进行操作。在给Realsense相机进行标定之前我们需要：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;安装最新的Intel® RealSense™ SDK 2.0&lt;/li&gt;
  &lt;li&gt;安装Realsense与ROS通信的Package：realsense-ros&lt;/li&gt;
  &lt;li&gt;安装用于相机标定的Package：camera_calibration&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;安装依赖package&quot;&gt;安装依赖Package&lt;/h2&gt;

&lt;p&gt;​		  首先是安装最新的Intel® RealSense™ SDK 2.0，可以按照官方repo的&lt;a href=&quot;https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md#installing-the-packages&quot;&gt;文档&lt;/a&gt;进行安装。首先添加注册服务器的public key，之后检查代理配置，接下来就是将服务器加入到仓库列表中安装需要的四个package即可：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-key adv --keyserver keys.gnupg.net --recv-key C8B3A55A6F3EFCDE || sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key C8B3A55A6F3EFCDE
export http_proxy=&quot;http://&amp;lt;proxy&amp;gt;:&amp;lt;port&amp;gt;&quot;

sudo add-apt-repository &quot;deb http://realsense-hw-public.s3.amazonaws.com/Debian/apt-repo xenial main&quot; -u
sudo apt-get install librealsense2-dkms
sudo apt-get install librealsense2-utils
sudo apt-get install librealsense2-dev
sudo apt-get install librealsense2-dbg
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  如果需要更新一个功能包可以使用这两句命令：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get update
sudo apt-get upgrade
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  接下来是安装Realsense与ROS通信的Package：realsense-ros。首先是进入到我们ROS的工作空间中将Package的代码下载下来并切换到对应的分支，之后就是编译和进行安装：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd ~/catkin_ws/src
git clone https://github.com/IntelRealSense/realsense-ros.git
cd realsense-ros/
git checkout `git tag | sort -V | grep -P &quot;^\d+\.\d+\.\d+&quot; | tail -1`
cd ..
catkin_make clean
catkin_make -DCATKIN_ENABLE_TESTING=False -DCMAKE_BUILD_TYPE=Release
catkin_make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  在安装之前需要确保依赖项已经安装过，在这一节课我们假设你已经学习过前面的课程并安装了必要的功能包。如果在编译过程中出错可以直接尝试使用下面这行命令获取缺失的功能包：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install ros-kinetic-缺失的功能包
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  在编译好之后将Realsense相机通过USB线连接到电脑上后，可以使用这行命令检查是否安装成功并驱动相机：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;roslaunch realsense2_camera rs_camera.launch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  出现了下面的结果就说明安装成功了：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../09/相机驱动成功.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;​		  可用&lt;code class=&quot;highlighter-rouge&quot;&gt;rosrun rqt_image_view rqt_image_view&lt;/code&gt;选择&lt;code class=&quot;highlighter-rouge&quot;&gt;/camera/color/image_raw&lt;/code&gt;查看相机收到的图像信息。需要说明的是，相机获取图像信息是有一个帧率的，如果你的计算机无法处理高帧率的图像可以在launch文件中修改&lt;code class=&quot;highlighter-rouge&quot;&gt;color_fps&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;depth_fps&lt;/code&gt;等参数以防止出现溢出现象。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../09/相机图像.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;​		  最后一部分就是安装用于相机标定的Package：camera_calibration。这个Package的安装可以参考&lt;a href=&quot;http://wiki.ros.org/camera_calibration&quot;&gt;ROS Wiki&lt;/a&gt;的内容，首先将放在Github托管的程序下载在你的ROS工作空间里，&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd ~/catkin_ws/src
git clone -b kinetic https://github.com/ros-perception/image_pipeline
cd ../
catkin_make
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  或者也可以简单粗暴的使用apt-get进行安装：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install ros-kinetic-camera-calibration
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;realsense相机标定&quot;&gt;Realsense相机标定&lt;/h2&gt;

&lt;p&gt;​		  之后可以选择自己打印或者购买相机标定需要的标定板，本节课中我们使用的标定板型号为&lt;code class=&quot;highlighter-rouge&quot;&gt;GP150-12*9&lt;/code&gt;，有了标定板之后就可以开始进行相机标定了：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;roslaunch realsense2_camera rs_camera.launch
rosrun camera_calibration cameracalibrator.py --size 11x8 --square 0.01 image:=/camera/color/image_raw camera:=/camera --no-service-check
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  如上面的命令所示，首先需要启动我们的realsense相机，之后再调用相机标定的程序，之后的参数分别是标定板的型号、方块的边长、图像的话题和相机的前缀。需要注意的是我们购买的标定板显示的是12*9，但是在运行程序时输入的参数&lt;code class=&quot;highlighter-rouge&quot;&gt;size&lt;/code&gt;指的是角点的数量，因此需要设置为11*8程序才能正常运行；除此之外，由于realsense相机并没有提供&lt;code class=&quot;highlighter-rouge&quot;&gt;/set_camera_info&lt;/code&gt;的服务，因此需要在参数中增加&lt;code class=&quot;highlighter-rouge&quot;&gt;--no-service-check&lt;/code&gt;，而且标定完成后的的结果只能保存而不能直接应用给相机。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../09/相机标定程序示意图.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;​		  如上图所示，正确运行的程序可以看到很多被彩色点标注的角点，在标定时需要按照X方向、Y方向、垂直方向也就是远近和倾斜一共四个因素移动标定板，直到每一个横条都显示为绿色时就可以点击&lt;code class=&quot;highlighter-rouge&quot;&gt;Calibrate&lt;/code&gt;计算内参矩阵了，计算需要耗时半分钟或者更久，结束之后点击&lt;code class=&quot;highlighter-rouge&quot;&gt;Save&lt;/code&gt;保存标定的结果就可以啦！标定的结果如下所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../09/标定矩阵结果.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;​		  在ost.yaml和ost.txt中记录了相机标定得到的内参矩阵，之后我们可以在编程中使用OpenCV或其他你喜欢的工具调用这一矩阵对获得的图像进行去畸变的操作，这部分内容我们就不在本课程中进行介绍了。接下来让我们简短的介绍如何使用笔记本电脑自带的相机进行标定。&lt;/p&gt;

&lt;h2 id=&quot;usb相机标定&quot;&gt;USB相机标定&lt;/h2&gt;

&lt;p&gt;​		  首先使用下面这行命令去安装usb相机在ROS下的驱动程序：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install ros-kinetic-usb-cam
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  通常不会出现什么问题，接下来就和之前的内容一样启动&lt;code class=&quot;highlighter-rouge&quot;&gt;camera_calibration&lt;/code&gt;程序，不过要根据usb_cam的话题消息进行一些改变：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rosrun camera_calibration cameracalibrator.py --size 11x8 --square 0.01 image:=/usb_cam/image_raw camera:=/usb_cam
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		  之后便是一样的标定过程，需要说明的是标定计算结束并成功保存时将会出现下面的画面，保存的文件位置在&lt;code class=&quot;highlighter-rouge&quot;&gt;/tmp/calibrationdata.tar.gz&lt;/code&gt;：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../09/标定结果保存终端示意图.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;​		  在本节课中我们介绍了Intel® RealSense D415相机的SDK和驱动程序的安装，ROS中相机标定程序camera_calibration的安装，演示了使用D415相机和笔记本电脑的usb相机进行内参标定的方法和注意事项。&lt;/p&gt;</content><author><name>James</name></author><category term="ROS手眼标定" /><summary type="html">ROS 内参标定</summary></entry><entry><title type="html">内参标定理论介绍</title><link href="http://localhost:4000/2019/08/09/%E5%86%85%E5%8F%82%E6%A0%87%E5%AE%9A%E7%90%86%E8%AE%BA%E4%BB%8B%E7%BB%8D.html" rel="alternate" type="text/html" title="内参标定理论介绍" /><published>2019-08-09T00:00:00+08:00</published><updated>2019-08-09T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/09/%E5%86%85%E5%8F%82%E6%A0%87%E5%AE%9A%E7%90%86%E8%AE%BA%E4%BB%8B%E7%BB%8D</id><content type="html" xml:base="http://localhost:4000/2019/08/09/%E5%86%85%E5%8F%82%E6%A0%87%E5%AE%9A%E7%90%86%E8%AE%BA%E4%BB%8B%E7%BB%8D.html">&lt;h1 id=&quot;内参标定理论介绍&quot;&gt;内参标定理论介绍&lt;/h1&gt;

&lt;p&gt;​		  在任何使用到相机的任务中，相机的内参标定都是一定要进行的，不过大多数购买到的相机都已经进行了提前的标定，不过为了能够更全面的掌握机械臂的手眼标定，我们还是需要掌握相机内参标定的方法。在这节课程中我们将会详细介绍张正友的经典论文&lt;code class=&quot;highlighter-rouge&quot;&gt;A Flexible New Technique fro Camera Calibration&lt;/code&gt;中提出的基于棋盘格的相机标定方法，在之后的课程中也会从实操角度介绍在ROS中如何对相机的内参进行标定。&lt;/p&gt;

&lt;h2 id=&quot;研究重心&quot;&gt;研究重心&lt;/h2&gt;

&lt;p&gt;​		  在学习一个新知识点之前首先需要明确这个问题的重心在哪里，使用的方法又是什么，这样才能够发现问题并有希望作出改进。在获取相机内参数的问题中，我们的核心在于使用已知的变量合理的表示内参数，并使用优化方法最终进行求解。在此之前我们先了解一下何为内参数：&lt;/p&gt;

&lt;p&gt;​		  在使用针孔相机获取三维世界的图像信息时需要经历这样几个过程：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先将三维世界中的一点$P=(X,Y,Z)$从世界坐标系通过刚体变换变换到相机所在的坐标系，需要的参数为旋转矩阵$R$和平移向量$t$，称为外参数；&lt;/li&gt;
  &lt;li&gt;获得了点$P$在相机坐标系下的坐标后，通过针孔相机的模型变换为成像平面上的点$p=(x,y)$；&lt;/li&gt;
  &lt;li&gt;将点$p$从成像平面通过缩放和平移变换变换到像素坐标系上的点$p=(u,\nu)$。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;​         若将其转换为矩阵相乘的形式可以写成下面的式子：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
s
 \left(
 \begin{matrix}
   u \\
   \nu \\
   1 
  \end{matrix}
  \right)
 =
 \left[
 \begin{matrix}
   \alpha &amp; 0 &amp; c_x \\
   0 &amp; \beta &amp; c_y \\
   0 &amp; 0 &amp; 1
  \end{matrix}
  \right]
   \left[
 \begin{matrix}
   f &amp; 0 &amp; 0 &amp; 0 \\
   0 &amp; f &amp; 0 &amp; 0 \\
   0 &amp; 0 &amp; 1 &amp; 0
  \end{matrix}
  \right]
   \left[
 \begin{matrix}
   R &amp; t \\
   0^T &amp; 1 
  \end{matrix}
  \right]
   \left(
 \begin{matrix}
   X \\
   Y \\
   Z \\
   1
  \end{matrix}
  \right)
  \\
  =
   \left[
 \begin{matrix}
   f_x &amp; 0 &amp; c_x &amp; 0 \\
   0 &amp; f_y &amp; c_y &amp; 0 \\
   0 &amp; 0 &amp; 1 &amp; 0
  \end{matrix}
  \right]
     \left[
 \begin{matrix}
   R &amp; t \\
   0^T &amp; 1 
  \end{matrix}
  \right]
     \left(
 \begin{matrix}
   X \\
   Y \\
   Z \\
   1
  \end{matrix}
  \right) %]]&gt;&lt;/script&gt;

&lt;p&gt;​		  内参数被记做$A$，它表示将坐标系从成像平面变换到像素坐标系的变换矩阵：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A=
 \left[
 \begin{matrix}
   f_x &amp; 0 &amp; c_x \\
   0 &amp; f_y &amp; c_y \\
   0 &amp; 0 &amp; 1
  \end{matrix}
  \right] %]]&gt;&lt;/script&gt;

&lt;p&gt;​		  而之前所说的外参数$R$和$t$则有上式中的这个矩阵进行表示：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left[
 \begin{matrix}
   R &amp; t \\
   0^T &amp; 1 
  \end{matrix}
  \right] %]]&gt;&lt;/script&gt;

&lt;p&gt;​		  其中$f_{x}=\alpha f$，$f_{y}=\beta f$。而$\alpha,\beta$分别表示图像上单位距离内$x$方向和$y$方向的像素个数，因此$f_x,f_y$将相机的焦距变换为在$x,y$方向上的像素度量表示。除此以外，为了不失一般性通常还会在内参矩阵$A$上增加一个参数$\gamma$：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
A=
 \left[
 \begin{matrix}
   f_x &amp; \gamma &amp; c_x \\
   0 &amp; f_y &amp; c_y \\
   0 &amp; 0 &amp; 1
  \end{matrix}
  \right] %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;射影变换&quot;&gt;射影变换&lt;/h2&gt;

&lt;p&gt;​		  在张正友标定法中使用棋盘格标定板进行相机标定，标定板平面是三维世界中的一个平面$\Pi$，而标定板映射到的像素坐标系下的像又是另一个平面$\pi$，因此可以使用射影变换实现两个平面之间的映射，而这只需要知道两个平面的对应点坐标即可求得两个平面之间的射影变换矩阵$H$。&lt;/p&gt;

&lt;p&gt;​		  在进行相机标定的时候，我们的标定板都是特制的具有确定型号的，而在运行标定程序时也需要将所使用的标定板的参数输入进去，在执行程序时提取标定板上角点的坐标，而对应角点在像素坐标系下图像的坐标可以通过程序来获取，因此便可以得到两个平面之间的映射。其之间的关系和之前描述的一样，改写成下式：
&lt;script type=&quot;math/tex&quot;&gt;p=A[R|t]P&lt;/script&gt;
​		  其中$p$是像素坐标，$P$是棋盘坐标，因此由刚才对射影变换矩阵的叙述可以得到：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H=A[R|t] \\
p=HP&lt;/script&gt;

&lt;p&gt;​		  设棋盘格所在平面为世界坐标系中$Z=0$的平面，这样棋盘格的任一角点P的世界坐标系为$(X,Y,0)$，则有：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s
 \left(
 \begin{matrix}
   u \\
   \nu \\
   1 
  \end{matrix}
  \right)
 =
A[R\ \ t]
   \left(
 \begin{matrix}
   X \\
   Y \\
   0 \\
   1
  \end{matrix}
  \right)
  =
  A[r_1\ \ r_2 \ \ r_3 \ \ t]
   \left(
 \begin{matrix}
   X \\
   Y \\
   0 \\
   1
  \end{matrix}
  \right)
  =
  A[r_1 \ \ r_2 \ \ t]
   \left(
 \begin{matrix}
   X \\
   Y \\
   1
  \end{matrix}
  \right)
  \\
  H = \lambda A[r_1 \ \ r_2 \ \ t] = [h_1 \ \ h_2 \ \ h_3]&lt;/script&gt;

&lt;p&gt;​		  将射影变换矩阵转化为这个形式之后，便可以使用棋盘平面和成像平面上对应的点计算射影变换矩阵了。&lt;/p&gt;

&lt;h2 id=&quot;结果推导&quot;&gt;结果推导&lt;/h2&gt;

&lt;p&gt;  由刚才的式子我们可以得到以下的等式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left\{
\begin{aligned}
r_1=\lambda A^{-1}h_1 \\
r_2=\lambda A^{-1}h_2 \\
t = \lambda A^{-1}h_3
\end{aligned}
\right.&lt;/script&gt;

&lt;p&gt;  而旋转矩阵$R$是正交矩阵，因此具有以下性质。也就是其列向量之间的内积为0，而每个列向量的模均为1：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r_1^T r_2=0 \\
||r_1||=||r_2||=1&lt;/script&gt;

&lt;p&gt;​		  至此，我们得到了在内参标定中非常重要的等式，它是对应与一个射影变换矩阵的约束式，它仅仅表示一对相对应的图像所表示的射影变换矩阵，而在实际操作中往往会取多对图像来计算射影变换矩阵：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
h_1^T(A^{-1})^TA^{-1}h_2 = 0\\
h_1^T(A^{-1})^TA^{-1}h_1 = h_2^T(A^{-1})^TA^{-1}h_2 = 1
\end{cases}&lt;/script&gt;

&lt;p&gt;​		  现在让我们把上式中间那部分矩阵$(A^{-1})^TA^{-1}$改写一下，改写成下面这个矩阵，具体的推导太过于复杂不在这里介绍，感兴趣的可以翻看本节课资料中的论文原件进行研读：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
B=(A^{-1})^TA^{-1}=
\left[
 \begin{matrix}
   B_{11} &amp; B_{12} &amp; B_{13} \\
   B_{21} &amp; B_{22} &amp; B_{23} \\
   B_{31} &amp; B_{32} &amp; B_{33}
  \end{matrix}
\right]
=
\left[
 \begin{matrix}
   \frac{1}{\alpha ^2} &amp; -\frac{\gamma}{\alpha^2\beta} &amp; \frac{v_0\gamma-u_0\beta}{\alpha^2\beta} \\
   -\frac{\gamma}{\alpha^2\beta} &amp; \frac{\gamma^2}{\alpha^2\beta^2}+\frac{1}{\beta^2} &amp; -\frac{\gamma(v_0\gamma-u_0\beta)}{\alpha^2\beta^2}-\frac{v_0}{\beta^2} \\
   \frac{v_0\gamma-u_0\beta}{\alpha^2\beta} &amp; -\frac{\gamma(v_0\gamma-u_0\beta)}{\alpha^2\beta^2}-\frac{v_0}{\beta^2} &amp; \frac{(v_0\gamma-u_0\beta)^2}{\alpha^2\beta^2}+\frac{v_0}{\beta^2}+1
  \end{matrix}
\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;​		  可以看到这个矩阵是一个对称矩阵，因此其仅具有6个未知量，可以将其写成更为紧凑的格式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b=[B_{11},B_{12},B_{22},B_{13},B_{23},B_{33}]&lt;/script&gt;

&lt;p&gt;​		  接下来就应该结合刚才的约束方程来推导得到射影变换矩阵的表达形式了，令$h_i$为矩阵$H$的第$i$个行向量即$h_i=[h_{i1}, h_{i2}, h_{i3}]^T$，则结合之前式子有：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_i(A^{-1})^TA^{-1}h_j = h_iBh_j=v_{ij}^Tb&lt;/script&gt;

&lt;p&gt;其中$v_{ij}=[h_{i1}h_{j1},h_{i1}h_{j2}+h_{i2}h_{j1},h_{i2}h_{j2},h_{i3}h_{j1}+h_{i1}h_{j3},h_{i3}h_{j2}+h_{i2}h_{j3},h_{i3}h_{j3}]$&lt;/p&gt;

&lt;p&gt;​		  因此可以将约束方程改写为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
h_1^T(A^{-1})^TA^{-1}h_2 = 0\\
h_1^T(A^{-1})^TA^{-1}h_1 = h_2^T(A^{-1})^TA^{-1}h_2 = 1
\end{cases}
\Rightarrow
\begin{cases}
v_{22}^Tb = 0\\
v_{11}b=v_{12}b
\end{cases}&lt;/script&gt;

&lt;p&gt;​		  写成矩阵形式有：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left[
\begin{matrix}
v_{12}^T \\
v_{11}-v_{22}
\end{matrix}
\right]
b
= Vb =0&lt;/script&gt;

&lt;p&gt;​		  这是仅仅使用一对图像计算射影变换矩阵时的方程，当采集到了多组图像时只需要将对应的$V$矩阵进行拼接即可。对于方程$Vb=0$的求解问题，最常见的方法就是最小二乘法，而在现代方法中常常使用$SVD$分解来求解这类问题，对SVD分解感兴趣的同学可以自行查找，这是一个十分常见的方法。在张正友论文的附录中给出了内参矩阵的计算方法：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
v_0 = (B_{12}B_{13}-B_{11}B_{23})/(B_{11}B_{22}-B_{12}^2) \\
u_0 = \gamma v_0/\beta - B_{13}\alpha^2/\lambda \\
\lambda = B_{33}-[B_{13}^2+v_0(B_{12}B_{13}-B_{11}B_{23})]/B_{11} \\
\alpha = \sqrt{\lambda / B_{11}} \\
\beta = \sqrt{\lambda B_{11} / (B_{11}B_{22}-B_{12}^2)} \\
\gamma = -B_{12}\alpha^2\beta / \lambda
\end{cases}&lt;/script&gt;

&lt;h2 id=&quot;消除畸变&quot;&gt;消除畸变&lt;/h2&gt;

&lt;p&gt;​		  在真实的相机中会因为光学透镜固有的问题而产生透视失真，通常可以将其分为枕形畸变、桶形畸变和线性畸变，其中枕形畸变和桶形畸变由于是径向对称的，因此也被称为径向畸变，使用下面的式子来表示径向畸变：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x} = x + x[k_1(x^2+y^2)+k_2(x^2+y^2)^2] \\
\hat{y} = y + y[k_1(x^2+y^2)+k_2(x^2+y^2)^2]&lt;/script&gt;

&lt;p&gt;​		  其中$k_1,k_2$表示径向畸变的系数，而且径向畸变的中心是相机的中心，则有：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\mu} = \mu + (\mu-\mu_0)[k_1(x^2+y^2)+k_2(x^2+y^2)^2] \\
\hat{\nu} = \nu + (\nu-\nu_0)[k_1(x^2+y^2)+k_2(x^2+y^2)^2]&lt;/script&gt;

&lt;p&gt;​		  继续将上式改写成矩阵形式，这个式子是从一幅图像上取点得到的，假设有$n$幅图像和$m$个图像点，那么便可以得到$2mn$个方程：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left[
\begin{matrix}
(\mu-\mu_0)(x^2+y^2) &amp; (\mu-\mu_0)(x^2+y^2)^2 \\
(\nu-\nu_0)(x^2+y^2) &amp; (\nu-\nu_0)(x^2+y^2)^2
\end{matrix}
\right]
\left[
\begin{matrix}
k_1 \\
k_2
\end{matrix}
\right]
=
\left[
\begin{matrix}
\hat{\mu}-\mu \\
\hat{\nu}-\nu
\end{matrix}
\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;​		  之后同样可以使用SVD对矩阵进行分解进而得到畸变参数$k=[k_1,k_2]^T$的最小二乘解，在得到畸变参数后便可以先对图像进行去畸变处理，之后在使用进行过去畸变的图像来估计相机的内参：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Dk=d \\
k = [k_1 \ \ k_2]^T = (D^TD)^{-1}D^Td&lt;/script&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;​		  在本节课中详细的介绍了张正友的内参相机标定法，使用这一方法可以使用棋盘格标定板快速的获得相机的内参数。这一方法已经十分成熟，在实际使用中并不需要我们手写代码去实现这一功能，在下一节课中我们将会学习如何使用ROS中的程序快速的实现相机的内参标定。&lt;/p&gt;

&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;

&lt;p&gt;[1] https://baike.baidu.com/item/镜头畸变/5120871&lt;/p&gt;

&lt;p&gt;[2] https://www.cnblogs.com/wangguchangqing/p/8335131.html&lt;/p&gt;

&lt;p&gt;[3] Zhang, Z. A flexible new technique for camera calibration[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22(11):0-1334.&lt;/p&gt;</content><author><name>James</name></author><category term="ROS手眼标定" /><summary type="html">内参标定理论介绍</summary></entry><entry><title type="html">PyTorch 入门(2)</title><link href="http://localhost:4000/2019/08/05/PyTorch%E5%85%A5%E9%97%A8(2).html" rel="alternate" type="text/html" title="PyTorch 入门(2)" /><published>2019-08-05T00:00:00+08:00</published><updated>2019-08-05T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/05/PyTorch%E5%85%A5%E9%97%A8(2)</id><content type="html" xml:base="http://localhost:4000/2019/08/05/PyTorch%E5%85%A5%E9%97%A8(2).html">&lt;h1 id=&quot;pytorch入门2&quot;&gt;PyTorch入门(2)&lt;/h1&gt;

&lt;h2 id=&quot;分类任务&quot;&gt;分类任务&lt;/h2&gt;

&lt;p&gt;​		在分类任务中，需要对数据生成类别，我们通常不使用一个数字来表示类别比如1, 2, 3, 4, 5等，而是使用不同的神经元来表示类别，最终的输出类似于&lt;code class=&quot;highlighter-rouge&quot;&gt;0 0 1&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;0 1 0&lt;/code&gt;等，而用到的$Loss Function$也多使用&lt;code class=&quot;highlighter-rouge&quot;&gt;CrossEntropyLoss()&lt;/code&gt;，也就是交叉熵，最后需要使用&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.max(net(x), 1)[1]&lt;/code&gt;选出其中概率最大的作为选择的类别进行输出，其有两个维度&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.max(net(x), 1)[0]&lt;/code&gt;则是最大的数值，那么&lt;code class=&quot;highlighter-rouge&quot;&gt;[1]&lt;/code&gt;就是对应的神经元了。&lt;/p&gt;

&lt;p&gt;​		其他的部分和之前的都是一样的，在创建数据的时候使用了一个函数&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cat&lt;/code&gt;，这个函数把不同类别的数据放到了一起然后转换成想要的数据类型：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;n_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		其参数dim是指拼接哪一个维度的数据，默认为0，上面的程序就将数据的第0维进行拼接，从两个[100, 2]的张量变成了一个[200, 2]的张量。&lt;/p&gt;

&lt;p&gt;​		接下来在莫烦的教程中还有一个没有用过的函数&lt;code class=&quot;highlighter-rouge&quot;&gt;plt.scatter()&lt;/code&gt;，之前使用matplotlib绘图都是直接plot大法好，这个高级的东西还是第一次见。它的用法介绍如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyplot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'o'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vmax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linewidths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;参数&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;格式&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;作用&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;x,y&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;形如shape(n, )数组&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;输入数据&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;标量或形如shape(n, )数组，默认：20&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;size in points^2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;c&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;色彩或颜色序列，可选&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;C可以是一个RGB或者RGBA的二维行数组&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;marker&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;MarkerStyle，可选&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;cmap&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Colormap可选，默认None&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;​		具体可以参照https://blog.csdn.net/qiu931110/article/details/68130199中介绍的属性。在教程中执行了以下命令：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'RdYlGn'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		这其中，前两个是需要画出来的数据两个维度的值，&lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt;则使用了一个小技巧，直接使用数据的标签当做色彩来对不同类别的数据进行区分，而不用手动判断类别后再进行绘制，而&lt;code class=&quot;highlighter-rouge&quot;&gt;lw&lt;/code&gt;则是指线的宽度$linewidths$。&lt;/p&gt;

&lt;h2 id=&quot;快速搭建法&quot;&gt;快速搭建法&lt;/h2&gt;

&lt;p&gt;​		可以使用&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn.Sequential()&lt;/code&gt;直接替代先前的网络搭建部分，具体如下：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;net2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		可以看到，激活函数在这里也被当做一层网络写在了函数里。&lt;/p&gt;

&lt;h2 id=&quot;保存--恢复网络&quot;&gt;保存 &amp;amp; 恢复网络&lt;/h2&gt;

&lt;p&gt;​		有两种方式来进行网络的保存和提取，一种是保存整个网络，另一种是只保存网络中的参数：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'net.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'net_params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		前者占用的空间更大速度也更慢，区别体现在恢复网络的时候。保存整个网络的方法在恢复网络的时候无需新建一个网络，只需要：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'net.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		而只保存参数的方法则需要重建一个相同的网络再将参数放置到新建的网络中：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'net_params.pkl'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;批训练&quot;&gt;批训练&lt;/h2&gt;

&lt;p&gt;​		在PyTorch中可以使用&lt;code class=&quot;highlighter-rouge&quot;&gt;DataLoader&lt;/code&gt;进行简单的数据包装，经过包装后数据可以高效的迭代以进行训练，这一工具可以将自己的numpy array的数据转换成Tensor：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 先转换成 torch 能识别的 Dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TensorDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_tensor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 把 dataset 放入 DataLoader
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# torch TensorDataset format
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# mini batch size
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;               &lt;span class=&quot;c1&quot;&gt;# 要不要打乱数据 (打乱比较好)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;num_workers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# 多线程来读数据
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Epoch: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| Step: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| batch x: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;batch_x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'| batch y: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		之后运行的结果如下所示：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
Epoch:0 | Step:0 | batch x:[6. 7. 2. 3. 1.] | batch y:[5. 4. 9. 8. 10.]
Epoch:0 | Step:1 | batch x:[9. 10. 4. 8. 5.] | batch y:[2. 1. 7. 3. 6.]
Epoch:1 | Step:0 | batch x:[3. 4. 2. 9. 10.] | batch y:[8. 7. 9. 2. 1.]
Epoch:1 | Step:1 | batch x:[1. 7. 8. 5. 6.] | batch y:[10. 4. 3. 6. 5.]
Epoch:2 | Step:0 | batch x:[3. 9. 2. 6. 7.] | batch y:[8. 2. 9. 5. 4.]
Epoch:2 | Step:1 | batch x:[10. 4. 8. 1. 5.] | batch y:[1. 7. 3. 10. 6.]
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;关于variable-和-tensor&quot;&gt;关于Variable 和 Tensor&lt;/h2&gt;

&lt;p&gt;​		在学习莫烦的教程中关于优化器的部分时，我注意到了在新版本PyTorch中有关Variable和Tensor之间关系的改变，不过在官方文档中没有发现什么。&lt;/p&gt;

&lt;p&gt;​		在教程的视频中对从TensorDataset里获取到的batch数据进行了转换为Variable的操作，解释道是因为只有Variable才能进行自动求导，官方文档也是这么说的。但事实上在教程的代码中取消了这一操作，而在Pycharm的Python控制台中查看变量的类型时，可以清晰地看到所有数据都是Tensor类型的。&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# training
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EPOCH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Epoch: '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_his&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses_his&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l_his&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		询问了同学后得知Tensor变量只需要它的&lt;code class=&quot;highlighter-rouge&quot;&gt;require_grad&lt;/code&gt;属性是&lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;的就可以进行自动求导，经过查证果然如此！上述代码中的b_x和b_y的&lt;code class=&quot;highlighter-rouge&quot;&gt;require_grad&lt;/code&gt;属性是&lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;的，但是loss的&lt;code class=&quot;highlighter-rouge&quot;&gt;require_grad&lt;/code&gt;属性是&lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;的，这应该是在执行&lt;code class=&quot;highlighter-rouge&quot;&gt;loss_func&lt;/code&gt;时为其加上的属性，这样便能够进行&lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt;操作了！&lt;/p&gt;

&lt;p&gt;​		（所以事实证明Python Console是个好东西）&lt;/p&gt;</content><author><name>James</name></author><category term="PyTorch" /><summary type="html">PyTorch入门(2)</summary></entry><entry><title type="html">PyTorch 入门(1)</title><link href="http://localhost:4000/2019/08/02/PyTorch%E5%85%A5%E9%97%A8(1).html" rel="alternate" type="text/html" title="PyTorch 入门(1)" /><published>2019-08-02T00:00:00+08:00</published><updated>2019-08-02T00:00:00+08:00</updated><id>http://localhost:4000/2019/08/02/PyTorch%E5%85%A5%E9%97%A8(1)</id><content type="html" xml:base="http://localhost:4000/2019/08/02/PyTorch%E5%85%A5%E9%97%A8(1).html">&lt;h1 id=&quot;pytorch&quot;&gt;PyTorch&lt;/h1&gt;

&lt;h2 id=&quot;pytorch-中的求导&quot;&gt;Pytorch 中的求导&lt;/h2&gt;

&lt;p&gt;​		在Pytorch中的&lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt;是用于计算图的求导的，首先变量有一个requires_grad参数，如果设置为$True$则需要进行求导，在求导过程中：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		是对其最后方设置了&lt;code class=&quot;highlighter-rouge&quot;&gt;requires_grad=True&lt;/code&gt;的变量进行求导，例如下面这段程序，我们将从它及其它的变体来理解&lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt;：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.autograd&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;v_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_1&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;v_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;variable.grad: &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		上面这段程序是很好理解的，由于variable是最后方设置了&lt;code class=&quot;highlighter-rouge&quot;&gt;requires_grad=True&lt;/code&gt;的参数，因此在执行&lt;code class=&quot;highlighter-rouge&quot;&gt;v_2.backward()&lt;/code&gt;的时候就相当于对&lt;code class=&quot;highlighter-rouge&quot;&gt;variable&lt;/code&gt;求导，最终的结果如下所示：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;variable.grad: 
 tensor([12.])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		结果自然就是$3\times 4=12$了，但需要说明的是&lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt;方法不支持对非标量进行求导，因此提供了一个$gradient$参数用骚操作实现对非标量求导。在执行&lt;code class=&quot;highlighter-rouge&quot;&gt;out.backward(gradient)&lt;/code&gt;的时候，如果out不是一个标量，那么先构造一个标量的值：&lt;code class=&quot;highlighter-rouge&quot;&gt;L = torch.sum(z*gradient)&lt;/code&gt;，再计算关于L对各个叶子变量的梯度。因此&lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt;在没有任何参数时相当于执行了&lt;code class=&quot;highlighter-rouge&quot;&gt;out.backward(gradient=torch.FloatTensor([1]))&lt;/code&gt;，也就是在结果上乘了一个1再求导，这也解释了为什么在&lt;code class=&quot;highlighter-rouge&quot;&gt;gradient=torch.FloatTensor([2])&lt;/code&gt;的时候结果会乘2。&lt;/p&gt;

&lt;p&gt;​		最后说明一下，&lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt;的求导是真真切切的对变量求导，变量的平方的求导和变量的拷贝乘平方的结果是不一样的！&lt;/p&gt;

&lt;h2 id=&quot;建立神经网络&quot;&gt;建立神经网络&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;unsqueeze(torch.linspace(-1, 1, 100), dim=1)&lt;/code&gt;：由于torch只能处理二维的数据，因此需要用这个操作增加一个维度（从0开始），比如这个语句就实现了从&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.Size([100])&lt;/code&gt;到&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.Size([100, 1])&lt;/code&gt;的转换。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;class Net(torch.nn.Module):&lt;/code&gt;：在定义网络的时候需要继承torch中神经网络的模型&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn.Module&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;forward()&lt;/code&gt;：每一个网络中都会有这个方法&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;​    在此叙述一下使用torch搭建网络所需要环节和步骤。首先是一个描述网络的类，其元素和方式在上面已经列出，其中在初始化函数使用&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn&lt;/code&gt;的各种层来对网络进行描述，在&lt;code class=&quot;highlighter-rouge&quot;&gt;forward()&lt;/code&gt;中对网络的结构进行描述：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hidden_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		在完成了对网络的描述后需要进行训练或者说学习，在学习时需要构建损失函数和优化器，在构建优化器的时候需要将网络的参数传进去并设置学习率：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		至于训练，则需要使用网络计算对应x的输出&lt;code class=&quot;highlighter-rouge&quot;&gt;prediction&lt;/code&gt;，之后使用预设的损失函数计算&lt;code class=&quot;highlighter-rouge&quot;&gt;loss&lt;/code&gt;，接下来首先将优化器的梯度置为0，这是因为每次优化结束梯度仍然会保持上一次的结果，然后对loss这个Variable变量进行&lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt;操作，最后执行优化器的梯度下降操作：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;​		&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt;这一步至关重要！一定不要忘记！&lt;/p&gt;</content><author><name>James</name></author><category term="PyTorch" /><summary type="html">PyTorch</summary></entry><entry><title type="html">Test Jekyll</title><link href="http://localhost:4000/2019/07/25/test-jekyll.html" rel="alternate" type="text/html" title="Test Jekyll" /><published>2019-07-25T00:00:00+08:00</published><updated>2019-07-25T00:00:00+08:00</updated><id>http://localhost:4000/2019/07/25/test-jekyll</id><content type="html" xml:base="http://localhost:4000/2019/07/25/test-jekyll.html">&lt;blockquote&gt;
  &lt;p&gt;Transform your plain text into static websites and blogs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;welcome&quot;&gt;Welcome&lt;/h1&gt;

&lt;h2 id=&quot;welcome-1&quot;&gt;Welcome&lt;/h2&gt;

&lt;h3 id=&quot;welcome-2&quot;&gt;Welcome&lt;/h3&gt;

&lt;p&gt;This site aims to be a comprehensive guide to Jekyll. We’ll cover topics such as getting your site up and running, creating and managing your content, customizing the way your site works and looks, deploying to various environments, and give you some advice on participating in the future development of Jekyll itself.&lt;/p&gt;

&lt;h3 id=&quot;so-what-is-jekyll-exactlypermalink&quot;&gt;So what is Jekyll, exactly?Permalink&lt;/h3&gt;

&lt;p&gt;Jekyll is a simple, blog-aware, static site generator. It takes a template directory containing raw text files in various formats, runs it through a converter (like &lt;a href=&quot;https://daringfireball.net/projects/markdown/&quot;&gt;Markdown&lt;/a&gt;) and our &lt;a href=&quot;https://github.com/Shopify/liquid/wiki&quot;&gt;Liquid&lt;/a&gt; renderer, and spits out a complete, ready-to-publish static website suitable for serving with your favorite web server. Jekyll also happens to be the engine behind GitHub Pages, which means you can use Jekyll to host your project’s page, blog, or website from GitHub’s servers for free.&lt;/p&gt;

&lt;h3 id=&quot;helpful-hintspermalink&quot;&gt;Helpful HintsPermalink&lt;/h3&gt;

&lt;p&gt;Throughout this guide there are a number of small-but-handy pieces of information that can make using Jekyll easier, more interesting, and less hazardous. Here’s what to look out for.&lt;/p&gt;

&lt;h3 id=&quot;video-test&quot;&gt;Video Test&lt;/h3&gt;

&lt;iframe type=&quot;text/html&quot; width=&quot;100%&quot; height=&quot;385&quot; src=&quot;http://www.youtube.com/embed/gfmjMWjn-Xg&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;</content><author><name>James</name></author><category term="test" /><summary type="html">Transform your plain text into static websites and blogs. Welcome Welcome Welcome This site aims to be a comprehensive guide to Jekyll. We’ll cover topics such as getting your site up and running, creating and managing your content, customizing the way your site works and looks, deploying to various environments, and give you some advice on participating in the future development of Jekyll itself. So what is Jekyll, exactly?Permalink Jekyll is a simple, blog-aware, static site generator. It takes a template directory containing raw text files in various formats, runs it through a converter (like Markdown) and our Liquid renderer, and spits out a complete, ready-to-publish static website suitable for serving with your favorite web server. Jekyll also happens to be the engine behind GitHub Pages, which means you can use Jekyll to host your project’s page, blog, or website from GitHub’s servers for free. Helpful HintsPermalink Throughout this guide there are a number of small-but-handy pieces of information that can make using Jekyll easier, more interesting, and less hazardous. Here’s what to look out for. Video Test</summary></entry><entry><title type="html">LOAM论文研读</title><link href="http://localhost:4000/2019/07/25/LOAM%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB.html" rel="alternate" type="text/html" title="LOAM论文研读" /><published>2019-07-25T00:00:00+08:00</published><updated>2019-07-25T00:00:00+08:00</updated><id>http://localhost:4000/2019/07/25/LOAM%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB</id><content type="html" xml:base="http://localhost:4000/2019/07/25/LOAM%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB.html">&lt;h1 id=&quot;loam论文研读&quot;&gt;LOAM论文研读&lt;/h1&gt;

&lt;p&gt;​		下面让我们从3D激光SLAM的常用算法LOAM来入手，从提出这个算法的论文开始逐步剖析，了解3D激光SLAM面临的困难及解决方案。&lt;/p&gt;
&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;
&lt;p&gt;​		首先在提出LOAM算法的论文（Low-drift and Real-time Lidar Odom and Mapping）中，作者提出了一种仅使用在六自由度环境下移动的3D激光雷达获取到的数据进行实时、低漂移的里程计和建图算法。实际上，这个问题并没有描述中的那么简单，由于激光雷达这个传感器结构的特殊性，其数据是在不同时刻采集到的，因此会导致点云数据的错误配准进而影响建图。为了解决这些问题，大多数3D激光SLAM算法都会进行回环检测来减少传感器带来的累计漂移，但是在LOAM中并没有回环检测这一手段，而是将SLAM问题拆分为两个子算法：里程计和建图。前者以较高的频率但是较低的精度实现对激光雷达的速度估计，而后者则以较前一个算法的频率低一个数量级的频率对激光雷达的数据进行匹配和点云的配准，通过这两个算法的结合就能实现实时建图的任务。算法的流程图如下所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../25/算法流程图.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt; 图1  LOAM算法流程图 &lt;/div&gt;
&lt;h2 id=&quot;符号说明&quot;&gt;符号说明&lt;/h2&gt;

&lt;p&gt;​		接下来将会出现一系列的公式和符号，为了不产生混淆我们先在此进行介绍，之后的讲解中如有不理解的仍然会停下来进行说明，不过为了能够更快的继续我的们的课程，提前进行符号说明是必须的：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;$P^{k}$：表示在第$k$次扫描时获取到的点云数据&lt;/p&gt;

  &lt;p&gt;$X_{k,i}^{L}$：表示在第$k$次扫描时，在激光雷达坐标系{$L$}下的一个点$i$&lt;/p&gt;

  &lt;p&gt;$X_{k,i}^{W}$：表示在第$k$次扫描时，在世界坐标系{$W$}下的一个点$i$&lt;/p&gt;

  &lt;p&gt;$T_{k}^{L}(t)$：表示在时刻$t$将一个点映射到第k次扫描起始时的坐标系下的变换（由于运动畸变）&lt;/p&gt;

  &lt;p&gt;$T_{k}^{W}(t)$：表示在时刻$t$将一个点映射到世界坐标系下的变换&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;激光里程计&quot;&gt;激光里程计&lt;/h2&gt;

&lt;h3 id=&quot;特征点选取&quot;&gt;特征点选取&lt;/h3&gt;

&lt;p&gt;​		和许多SLAM算法一样，LOAM算法也使用特征点来计算坐标变换矩阵，因此我们的第一步便是从激光雷达获取到的点云中提取特征点，在LOAM中将特征点分为了两类：边缘点(Edge points)和平面点(Planar Points)。下面我们将会介绍如何在点云中提取这两类特征点。&lt;/p&gt;

&lt;p&gt;​		提取特征点的依据是这个点的曲率，选取在点云$P_{k}$中的点$i$，设集合$S$为与点$i$相邻的点的集合，那么点$i$处的曲率可以由下式得到：
&lt;script type=&quot;math/tex&quot;&gt;c=\frac{1}{|S|\cdot||X_{(k,i)}^{L}||}||\sum_{j\in S,j\ne i}(X_{(k,i)}^{L}-X_{(k,j)}^{L})||&lt;/script&gt;
​		在实际应用中我们通常使用点$i$周围几个点来计算该点的曲率，得到了曲率后我们根据$c$值对各点进行排序，其中$c$值最大的被选为边缘点而最小的被选为平面点。在论文中，作者为了让特征点能够在全空间内分布的更加均匀，将每一次扫描分为四个子区域，每一个子区域最多可以提供2个边缘特征点和4个平面特征点，而且均需要和阈值$5\times10^{-3}$进行比较才能确定是否为特征点。&lt;/p&gt;

&lt;p&gt;​		除此之外，由于传感器的数据不可能是完全精确的而且现实的环境又是多种多样极其复杂的，在选取特征点的时候需要避开可能造成错误的特征点，在LOAM中就对特征点的选取给出了限制：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;特征点的数量不应该超过子区域对特征点数量的限制&lt;/p&gt;

  &lt;p&gt;应避免在已经被选择的点周围再次选择特征点&lt;/p&gt;

  &lt;p&gt;特征点不应该选取在和雷达平面的夹角在$10^{\circ}$以内平面上&lt;/p&gt;

  &lt;p&gt;特征点不应该选取在被遮挡的平面上&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;​		最主要的也最值得解释的是后两点限制，这两种情况的示意图如下图所示：&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../25/特征点选取示意图.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt; 图2 特征点选取示意图 &lt;/div&gt;
&lt;p&gt;​		在第一种情况下，需要通过$S$中的点构成的平面来计算和激光雷达平面的角度；而在第二种情况下，则需要对点$i$附近的点中是否存在与其相隔很远的点来进行检查，如果存在这样的点则说明点$i$是在被遮挡着的平面上（即上图中的C、D点），特征点提取的结果如图下所示，其中黄色的点表示边缘点而红色则表示平面点。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../25/特征点选取示意图2.png&quot; width=&quot;50%&quot; height=&quot;50%&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt; 图3 特征点选取结果示意图 &lt;/div&gt;
&lt;h3 id=&quot;特征点匹配&quot;&gt;特征点匹配&lt;/h3&gt;

&lt;p&gt;​		里程计算法用于估计激光雷达在一次扫描中的运动，我们设$t_{k}$为第$k$次扫描的起始时间，在第$k-1$次扫描的最后时刻将这一次扫描中采集到的点云数据映射到时间戳$t_{k}$上，这些被映射过的点云被记做$\bar P_{k-1}$，在第k次扫描中这部分数据和在第$k$次扫描时逐渐采集到的点云数据$P_{k}$一起估计激光雷达的运动。&lt;/p&gt;

&lt;p&gt;​		在这一部分中我们不考虑如何对点云进行映射，我们将在下一部分介绍如何得到所需的变换阵。我们设在点云集合$P_{k}$中边缘特征点的集合为$\varepsilon_{k}$，平面特征点的集合为$H_{k}$，我们接下来就需要在$\bar P_{k-1}$中寻找和这两个集合中元素匹配的点。需要注意的是在第$k$次扫描刚开始时，上述的集合都还是空集合，随着扫描时间的增加特征点的数量逐渐增加，因此我们需要将特征点映射到第$k$次扫描的起始时刻$t_{k}$，设映射后的点集为$\tilde\varepsilon_{k}$和$\tilde H_{k}$。对于映射后的集合中的每一个元素，在$\bar P_{k-1}$中寻找最近邻的点，其中$\bar P_{k-1}$是通过$KD-tree$进行储存的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先介绍边缘特征点如何进行匹配。对于在集合$\tilde\varepsilon_{k}$中的边缘特征点$i$首先在$\bar P_{k-1}$中寻找它的最近邻点$j$，之后在这个近邻点$j$所在的扫描面的前后两个扫描面上寻找与$i$最近邻的点$l$。那么边缘特征点的匹配就可以使用元组$(j,l)$来进行表示，但是这两个点都需要满足$c &amp;gt; 5\times10^{-3}$的条件。&lt;/li&gt;
  &lt;li&gt;接下来介绍平面特征点如何进行匹配。对于在集合$\tilde H_{k}$中的平面特征点$i$首先在$\bar{P}_{k-1}$中寻找它的最近邻点$j$，之后再寻找两个近邻点用来表示平面特征点的匹配，这两个点的其中一个是在这个近邻点$j$所在的扫描面选择的除点$j$之外的另一个近邻点，另一个是在其前后两个扫描面上选择的一个近邻点。那么平面特征点的匹配就可以使用元组$(j,l,m)$来进行表示。之所以这样选取是为了保证这三个一定是不共线的，当然和边缘特征点匹配中一样，同样需要保证这三个点满足$c &amp;lt; 5\times10^{-3}$的条件。特征点匹配的示意图如下所示：&lt;/li&gt;
&lt;/ul&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../25/特征点匹配示意图.png&quot; width=&quot;75%&quot; height=&quot;75%&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt; 图4 特征点匹配示意图 &lt;/div&gt;
&lt;p&gt;​		获得了匹配好的特征点后，我们可以通过特征点和与其匹配的边缘或平面之间的距离来对变换矩阵进行优化，具体的计算方式如下所示：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;边缘特征点和对应边缘之间的距离可以通过外积来求得。下式中的分子部分表示的是由$\vec{ij}$和$\vec{il}$为边组成的平行四边形的面积，而分子则表示$\vec{jl}$的长度，最终的结果便是点$i$到点$j$和$l$表示的边缘的距离：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d\varepsilon=\frac{|(\tilde X_{(k,i)}^{L}-\bar X_{(k-1,j)}^{L})\times(\tilde X_{(k,i)}^{L}-\bar X_{(k-1,l)}^{L})|}{|\bar X_{(k-1,j)}^{L}-\bar X_{(k-1,l)}^{L}|}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;平面特征点和对应平面之间的距离可以通过混合积来求得。下式中的分子部分表示的是由$\vec{jm}$、$\vec{jl}$和$\vec{ji}$为边组成的平行六面体的体积，而分子则表示底面的面积，最终的结果便是点$i$到底面的距离：&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d_{H}=\frac{|(\tilde X_{(k,i)}^{L}-\bar X_{(k-1,j)}^{L})\cdot((\bar X_{(k-1,j)}^{L}-\bar X_{(k-1,l)}^{L})\times(\bar X_{(k-1,j)}^{L}-\bar X_{(k-1,m)}^{L}))|}{|(\bar X_{(k-1,j)}^{L}-\bar X_{(k-1,l)}^{L})\times(\bar X_{(k-1,j)}^{L}-\bar X_{(k-1,m)}^{L})|}&lt;/script&gt;

&lt;p&gt;​		注意其中$X$上边符号的不同，$\tilde{}$表示的是在$\tilde{P_{k}}$中获得到的特征点，而$\bar{}$则表示的是在$\bar{P}_{k-1}$中获得到的前一次扫描中的特征点。&lt;/p&gt;

&lt;h3 id=&quot;动作估计&quot;&gt;动作估计&lt;/h3&gt;

&lt;p&gt;​		在这一部分中我们就开始介绍之前没有进行的动作估计，也就是获得在第$k$次扫描时的变换矩阵，这个变换矩阵是一个随时间发生变化的矩阵$T_{k}^{L}(t)$。这个变换矩阵表征了六个自由度上的变化，可以被拆分成两个部分，分别是旋转变换和平移变换：$T_{k}^{L}(t)=[\tau_{k}^{L}(t)$,$\theta_{k}^{L}(t)]^{T}$，其中$\tau_{k}^{L}(t)=[t_x,t_y,t_z]^{T}$，$\theta_{k}^{L}(t)=[\theta_x,\theta_y,\theta_z]^T$。可以使用罗德里格斯公式来计算对应的旋转矩阵：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{k}^{L}(t)=e^{\hat{\theta}_{k}^{L}(t)}=I+\frac{\hat{\theta}_{k}^{L}(t)}{||\theta_{k}^{L}(t)||}sin||\theta_{k}^{L}(t)||+(\frac{\hat{\theta}_{k}^{L}(t)}{||\theta_{k}^{L}(t)||})^2(1-||cos\theta_{k}^{L}(t)||)&lt;/script&gt;

&lt;p&gt;​		其中$\hat \theta_{k}^{L}(t)$表示$\theta_{k}^{L}(t)$的反对称矩阵，如果不清楚可以稍后随意查一下就行，或者只需要知道这是一个由$\theta_{k}^{L}(t)$中的元素组成的矩阵即可。得到了旋转矩阵后便可以使用获取到的点云数据将其映射回当前扫描的起始时刻$t_{k}$：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{X}_{(k,i)}^{L}=R_{(k,i)}^{L}X_{(k,i)}^{L}+\tau_{(k,i)}^{L}&lt;/script&gt;

&lt;p&gt;​		不知道大家还记不记得之前计算特征点和边缘与平面之间距离的公式，将上式与那两个公式联系起来便能简化成以下形式：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f_{\varepsilon}(X_{(k,i)}^{L}(t),T_{k}^{L}(t))=d\varepsilon,　i\in\varepsilon_{k}$&lt;/li&gt;
  &lt;li&gt;$f_{H}(X_{(k,i)}^{L}(t),T_{k}^{L}(t))=d_{H},　i\in H_{k}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;​		将上式进行统一即可得到以下的公式，我们可以使用列文伯格-马夸尔特优化算法不断地进行优化直至收敛或达到预设的迭代次数，进而得到期望的变换矩阵$T_{k}^{L}(t)$：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(T_{k}^{L}(t))=d&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;T_k^L(t)\leftarrow T_k^L(t)-(J^TJ+\lambda diag(J^TJ))^{-1}J^Td&lt;/script&gt;

&lt;p&gt;​		其中$J$为$f$对$T_k^L(t)$计算得到的$Jacobian$矩阵，$\lambda$是由列文伯格-马夸尔特算法决定的因子。&lt;/p&gt;

&lt;h3 id=&quot;激光里程计的整体算法&quot;&gt;激光里程计的整体算法&lt;/h3&gt;

&lt;p&gt;​		下面是我们刚才叙述的激光里程计算法的汇总，可以看到在第$k$次扫描时的输入为上一次扫描获得的点云映射在$t_k$时刻之后的结果，当前扫描获取到的点云信息和初始变换矩阵。按照刚刚讲解的顺序，先是从点云数据中提取了边缘特征点和平面特征点，之后又使用非线性优化方法对变换矩阵进行计算，当结束本次扫描后再将本次扫描获取到的点云数据使用上一步中计算得到的变换矩阵将点云数据映射到$t_{k+1}$时刻上，最后结束本次扫描并返回变换矩阵。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../25/激光里程计算法.png&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt; 图5 激光里程计算法 &lt;/div&gt;
&lt;h2 id=&quot;激光建图&quot;&gt;激光建图&lt;/h2&gt;

&lt;p&gt;​		激光建图的整个流程和激光里程计实质上并没有什么差别，只不过我们需要进行匹配的点云是地图点云$Q_{k-1}$而已。在下图中黑色部分的是已经建好的地图中的点云，绿色部分是我们在第$k$次扫描时获取到的点云数据映射到世界坐标系${W}$下的结果，蓝色的轨迹线是在第$k$次扫描以前激光雷达的运动轨迹，而橙色的轨迹线则表示在第$k$次扫描时激光雷达运动的轨迹。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;../25/建图示意图.png&quot; width=&quot;65%&quot; height=&quot;65%&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt; 图6 建图示意图 &lt;/div&gt;
&lt;p&gt;​		在建图中，由于采用更低的频率，我们也可以选择更多的特征点数，在论文中作者选择了十倍于里程计算法的特征点数，但是选择特征点的方式和依据没有改变。在建图中我们需要通过优化算法计算的主要是将激光雷达位姿映射到世界坐标系的变换$T_k^W(t)$，将之前用于优化的公式中的所有$T_k^L(t)$替换为$T_k^W(t)$并把在$P_k$中出现的点替换为在$Q_{k}$中出现的点即可：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f_{\varepsilon}(Q_{(k,i)}(t),T_{k}^{W}(t))=d\varepsilon,　i\in\varepsilon_{k}$&lt;/li&gt;
  &lt;li&gt;$f_{H}(Q_{(k,i)}(t),T_{k}^{L}(t))=d_{H},　i\in H_{k}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;​		之后仍然是使用列文伯格-马夸尔特算法进行优化实现建图操作，至此我们的论文解析就结束了，在LOAM中仅使用了激光雷达的点云数据，通过两个子算法激光里程计和激光建图实现了低漂移的3D激光SLAM。&lt;/p&gt;</content><author><name>James</name></author><category term="3D_SLAM" /><summary type="html">LOAM论文研读</summary></entry></feed>