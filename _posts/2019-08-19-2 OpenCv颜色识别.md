---
layout: post
title: '2 OpenCV颜色识别'
date: 2019-08-19
author: James
color: rgb(255,210,32)
cover: '../2019/08/09/time.png'
tags: 机械臂视觉结合
---

# OpenCV颜色识别

&#8195;&#8195;在机械臂抓取任务中，对物体进行识别是一件十分重要的事情，对物体进行识别的作用一是在于获取其位置以使机械臂末端到达该物体所在位置，二是获取其位姿以确定机械臂末端抓取装置的抓取位姿。

&#8195;&#8195;在本章中出于简化的目的，将机械臂的抓取任务改为控制机械臂末端到达指定位姿，如果想要实现抓取可以在本章学习的基础上进行拓展，一方面使用搭建环境中学到的内容添加抓取装置，另一方面在本小节学习的基础上增加基于深度学习的物体识别与计算抓取位姿的模块，再结合下一小节中的机械臂moveit!编程则可以实现全套的机械臂抓取任务。以下是物体识别和抓取姿态分析的常见API：

```
# 物体识别
http://wiki.ros.org/object_recognition
https://github.com/tensorflow/models/tree/master/research/object_detection
# 抓取姿态
http://wiki.ros.org/agile_grasp
http://wiki.ros.org/moveit_simple_grasps
http://wiki.ros.org/graspit
```

&#8195;&#8195;在本小节中我们将使用OpenCv和Python通过颜色进行阈值判断获取方块所在的位置，再通过订阅器和发布器实现与仿真环境的交互。在开始之前，我们最好梳理一下这个模块中需要哪些部分：

+ 用于接收仿真环境发布的图像消息的接收器
+ 用于对接收到的图像进行处理的回调函数
+ 用于发布处理结果的发布器

&#8195;&#8195;那么接下来就让我们开始进行颜色识别的编程实现吧！在`ur5_grasping`的scripts文件夹下新建一个recognition.py，要想能够通过rosrun运行这个程序，我们还需要在终端中输入下面命令将这个程序变为可执行程序：

```
cd ~/caktin_ws/src/ur5_grasping/scripts
chmod +x *
```

&#8195;&#8195;在程序的第一行要写上`#!/usr/bin/env python`来声明这是一个python文件，接下来就是import我们需要的头文件：

```python
import sys
import rospy
import cv2
import numpy as np
from geometry_msgs.msg import Pose
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
```

&#8195;&#8195;这些头文件中sys是用来获取终端中输入的参数的；rospy是ROS使用python编程的最重要的api，它提供了发布器和接收器等一系列重要功能；cv2则是OpenCv在Python中的api；numpy则是在Python中用于数组操作的最常用api；cv_bridge是在ROS中使用OpenCv进行图像处理最重要的api，它提供了ROS中图像消息类型和OpenCv可以处理的图像类型之间的转换；而那两个msg的import则是在程序中需要使用的消息类型，Pose是用于描述机械臂末端位姿的，Image则是ROS中的图像消息，可以通过`rosmsg show`进行查看：

<div align="center">
  <img src="../19/Image消息.png" width="75%" height="75%"/>
  <img src="../19/Pose消息.png" width="75%" height="75%"/>
</div>

&#8195;&#8195;接下来定义一个名为Recognition的类并编写初始化函数：

```python
class Recognition:
    def __init__(self):
        rospy.init_node('image_recongition', anonymous=True)
        self.image_sub = rospy.Subscriber('/camera/image_raw', Image, self.callback)
        self.can_pub = rospy.Publisher('/recognition/can', Image)
        self.location_pub = rospy.Publisher('/recognition/location', Pose)
        self.bridge = CvBridge()
        self.pose_goal = Pose()
        self.pose_goal.orientation.x = 0
        self.pose_goal.orientation.y = 0.707
        self.pose_goal.orientation.x = 0
        self.pose_goal.orientation.w = 0.707
```

&#8195;&#8195;在初始化函数中首先使用rospy初始化了一个名为`image_recognition`的节点，接下来是订阅相机话题消息的订阅器，它的回调函数是self.callback，我们将会后面进行介绍；之后是两个发布器，分别用于发布处理后的图像信息和机械臂末端应当到达的目标位姿；接下来的`self.bridge = CvBridge()`则声明了一个bridge实例，用于进行数据格式的转换；剩下的就是声明了一个Pose实例用来描述机械臂末端的目标位姿。

&#8195;&#8195;实际上，通过初始化函数，我们已经将这一模块的整体框架搭建好了，下面就是本模块最重要的回调函数了，所有的处理都在这里进行，下面就让我们来看一下如何编写这一回调函数。

&#8195;&#8195;最首要的事情就是使用cv_bridge将订阅器接收到的图像消息转换为cv_image：

```python
def callback(self, data):
	try:
		cv_image = self.bridge.imgmsg_to_cv2(data, 'bgr8')
	except CvBridgeError as e:
		print(e)
```

&#8195;&#8195;之后为了通过颜色更轻松的进行识别，需要将原来的RGB颜色空间转换到HSV颜色空间上来，不了解HSV颜色空间的可以自行查阅相关资料，简单来讲就是把对颜色的描述从三原色的合成转换成了色调H、饱和度S和明度V的合成：

```python
    # convert bgr image to hsv and find the can by threshold
    hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
    low_green_can = np.array([10, 200, 10])
    upper_green_can = np.array([255, 255, 255])
    mask = cv2.inRange(hsv, low_green_can, upper_green_can)
    res = cv2.bitwise_and(cv_image, cv_image, mask=mask)
```

&#8195;&#8195;之后在使用numpy array设置筛选的阈值将图像中绿色的部分筛选出来，其中mask表示对筛选出来的像素进行的标注，而res则表示将这些标注与原图像进行合成后的结果，应当是在一片漆黑的背景中有一团绿色的点，这就是通过颜色识别到的方块：

<div align="center">
  <img src="../19/res.png" width="75%" height="75%"/>
</div>

&#8195;&#8195;接下来使用的程序是OpenCv中用于标记轮廓使用到的一系列函数，首先将只有方块的那张图像res转换到灰度空间上：

```python
    # find the center of the can
    imgray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)
    ret, thresh = cv2.threshold(imgray, 100, 255, 0)
    image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
    img_contour = cv2.drawContours(cv_image, contours, 0, (0,0,255), 2)
```

&#8195;&#8195;之后再次通过阈值提取到方块占据的像素区域，接下来使用寻找轮廓的函数获得在上一步中选中区域的轮廓contours，接下来使用drawContours在原图中标注轮廓：

<div align="center">
  <img src="../19/轮廓.png" width="75%" height="75%"/>
</div>

&#8195;&#8195;最后一步，计算方块的中心点。在OpenCv的轮廓处理的程序中，可以生成轮廓包含区域的矩，这些矩被保存在一个字典中，我们可以通过一个中学就学过的式子计算这个区域的重心，也就是程序中的cx和cy：

```python
    # compute the location of coke_can
    try:
        cnt = contours[0]
        M = cv2.moments(cnt)

        cx = int(M['m10']/M['m00'])
        cy = int(M['m01']/M['m00'])
        [hx, hy] = cv_image.shape[0:2]
        y = 0.1 * (800.0 / 90.0) * (hx / 2 - cx) / float(hx)       # the real scale
        x = 0.1 * (800.0 / 90.0) * (hy / 2 - cy) / float(hy) + 0.3 # the real scale
        self.pose_goal.position.x = x
        self.pose_goal.position.y = y
        self.pose_goal.position.z = 0.125
        self.location_pub.publish(self.pose_goal)
    except (ZeroDivisionError, IndexError) as e:
    	pass

    try:
    	self.can_pub.publish(self.bridge.cv2_to_imgmsg(img_contour, 'bgr8'))
    except CvBridgeError as e:
    	print(e)
```

&#8195;&#8195;接下来的一步通过图像和真实之间尺度变换来计算物块在仿真环境中的位置，也就是知道方块在图像中的像素坐标，然后将它映射到仿真环境中的坐标。在这个环节需要我们一些人工操作了，我是在上一小节搭建实验环境的时候改变了方块的位置来观察其在图像中坐标改变的像素数，借此推断出尺度变化的比例。在得到目标位姿后便可以发布修改过的`pose_goal`消息了：

<div align="center">
  <img src="../19/echo.png" width="75%" height="75%"/>
</div>

&#8195;&#8195;需要注意的是，由于在移动过程中机械臂会遮挡方块导致本模块无法检测到方块，这将会在获得区域以及计算其重心时报错，为了避免这样的情况干扰程序的运行，因此才需要使用`try - except`进行异常处理。

&#8195;&#8195;最后，在调用这个模块的时候记得使用`rospy.spin()`让其保持工作状态：

```python
if __name__ == '__main__':
    rec = Recognition()
    try:
        rospy.spin()
    except KeyboardInterrupt:
        print('Shutting Down!')
```

&#8195;&#8195;以上就是OpenCv颜色识别的全部内容，最主要的是在实现这一功能时清晰的思路，知道自己在干什么知道需要什么，下一节我们就将顺着在这一节中发布的位姿消息实现机械臂控制的功能。
